{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pickle\n",
    "\n",
    "# 🔹 주식 데이터 가져오기\n",
    "tickers = [\n",
    "    \"AAPL\",  # 애플\n",
    "    \"MSFT\",  # 마이크로소프트\n",
    "    \"GOOGL\",  # 구글(알파벳)\n",
    "]\n",
    "\n",
    "\n",
    "# # 🔹 주식 데이터 가져오기\n",
    "# tickers = [\n",
    "#     \"AAPL\",  # 애플\n",
    "#     \"MSFT\",  # 마이크로소프트\n",
    "#     \"GOOGL\",  # 구글(알파벳)\n",
    "#     \"TSLA\",  # 테슬라\n",
    "#     \"AMZN\",  # 아마존\n",
    "#     \"META\",  # 메타 (구 페이스북)\n",
    "#     \"NVDA\",  # 엔비디아\n",
    "#     \"NFLX\",  # 넷플릭스\n",
    "#     \"AMD\",  # AMD\n",
    "#     \"INTC\",  # 인텔\n",
    "#     \"PYPL\",  # 페이팔\n",
    "#     \"DIS\",  # 디즈니 (엔터테인먼트)\n",
    "#     \"PEP\",  # 펩시코 (소비재)\n",
    "#     \"KO\",  # 코카콜라 (소비재)\n",
    "#     \"XOM\",  # 엑슨모빌 (에너지)\n",
    "#     \"PFE\"   # 화이자 (제약)\n",
    "# ]\n",
    "\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    temp = stock.history(period=\"max\")[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "    temp[\"Ticker\"] = ticker\n",
    "    df_list.append(temp)\n",
    "\n",
    "# 🔹 데이터 병합\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "# 🔹 로그 변환 적용 (✅ MinMax 정규화 제거)\n",
    "df[\"Close\"] = np.log1p(df[\"Close\"])  # 로그 변환만 적용\n",
    "\n",
    "# 🔹 이동 평균 및 지표 추가\n",
    "df[\"MA_10\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.rolling(window=10).mean())\n",
    "df[\"MA_20\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.rolling(window=20).mean())\n",
    "df[\"STD_10\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.rolling(window=10).std())\n",
    "df[\"STD_20\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.rolling(window=20).std())\n",
    "\n",
    "# 🔹 RSI 지표 추가\n",
    "def compute_rsi(data, window=14):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "df[\"RSI_14\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: compute_rsi(x))\n",
    "df[\"MACD\"] = df.groupby(\"Ticker\")[\"Close\"].transform(lambda x: x.ewm(span=12, adjust=False).mean() - x.ewm(span=26, adjust=False).mean())\n",
    "df[\"MACD_Signal\"] = df.groupby(\"Ticker\")[\"MACD\"].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n",
    "\n",
    "# 🔹 거래량 이동 평균 및 로그 변환\n",
    "df[\"Volume_MA_10\"] = df.groupby(\"Ticker\")[\"Volume\"].transform(lambda x: x.rolling(window=10).mean())\n",
    "df[\"Volume_MA_20\"] = df.groupby(\"Ticker\")[\"Volume\"].transform(lambda x: x.rolling(window=20).mean())\n",
    "df[\"Log_Volume\"] = np.log1p(df[\"Volume\"])\n",
    "\n",
    "# 🔹 NaN 값 제거\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# ✅ 필요하지 않은 컬럼 삭제 (Ticker 삭제)\n",
    "df.drop(columns=[\"Open\", \"High\", \"Low\", \"Volume\", \"Ticker\"], errors='ignore', inplace=True)\n",
    "\n",
    "df_standardized = df.copy()\n",
    "df_standardized[df.columns.difference([\"Close\"])] =  np.log1p(df.drop(columns=[\"Close\"]))  # ✅ Close 제외 후 정규화\n",
    "\n",
    "df_standardized[\"Close\"] = df[\"Close\"]  # ✅ Close는 정규화하지 않고 로그 변환된 값 그대로 사용\n",
    "df_standardized1 = df_standardized.copy()\n",
    "\n",
    "\n",
    "# 🔹 50일 단위 시퀀스 데이터 생성\n",
    "sequence_length = 100\n",
    "output_length = 100\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(df_standardized) - sequence_length - output_length):\n",
    "    X.append(df_standardized.iloc[i : i + sequence_length].values)  \n",
    "    y.append(df_standardized.iloc[i + sequence_length : i + sequence_length + output_length][\"Close\"].values)  \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 🔹 데이터 분할\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_val = X[:split_idx], X[split_idx:]\n",
    "y_train, y_val = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 🔹 PyTorch 텐서 변환\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(model_class, patience=100) : \n",
    "    # ✅ GPU 메모리 정리 (불필요한 캐시 해제)\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 🔹 모델 초기화\n",
    "    model = model_class.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # ✅ 학습 루프 조기 종료 기준\n",
    "    best_val_rmse = float(\"inf\")\n",
    "    trigger_count = 0\n",
    "\n",
    "    # ✅ 평균 주가 계산 (로그 변환 전 복원)\n",
    "    avg_stock_price_exp = np.expm1(df[\"Close\"]).mean()  # 로그 변환 복원한 평균 주가\n",
    "\n",
    "    # 🔹 학습 루프\n",
    "    for epoch in range(500):\n",
    "        optimizer.zero_grad()\n",
    "        model.train()\n",
    "        predictions = model(X_train_tensor)\n",
    "        loss = criterion(predictions, y_train_tensor)\n",
    "        rmse = torch.sqrt(loss.mean())\n",
    "        mape = torch.mean(torch.abs((predictions - y_train_tensor) / y_train_tensor)) * 100\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_predictions = model(X_val_tensor)\n",
    "            val_loss = criterion(val_predictions, y_val_tensor)\n",
    "            val_rmse = torch.sqrt(val_loss.mean())\n",
    "            val_mape = torch.mean(torch.abs((val_predictions - y_val_tensor) / y_val_tensor)) * 100\n",
    "\n",
    "        # ✅ RMSE 로그 변환 복원 후 퍼센트 계산\n",
    "        rmse_exp = np.expm1(val_rmse.item())  # RMSE 값을 로그 변환 이전 값으로 복원\n",
    "        rmse_percentage = (rmse_exp / avg_stock_price_exp) * 100  # 퍼센트 계산\n",
    "\n",
    "        if val_rmse.item() < best_val_rmse:\n",
    "            best_val_rmse = val_rmse.item()\n",
    "            trigger_count = 0\n",
    "            torch.save(model.state_dict(), \"best_stock_predictor.pth\")  \n",
    "        else:\n",
    "            trigger_count += 1\n",
    "        \n",
    "        if trigger_count >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1} due to no improvement in Val RMSE\")\n",
    "            break\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/500], RMSE: {rmse.item():.4f}, MAPE: {mape.item():.2f}%, \"\n",
    "                f\"Val RMSE: {val_rmse.item():.4f} (Converted: {rmse_exp:.2f}), \"\n",
    "                f\"Val RMSE %: {rmse_percentage:.2f}%, Val MAPE: {val_mape.item():.2f}%\")\n",
    "            \n",
    "    del model\n",
    "    del optimizer\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순정 Transformer 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ 학습 루프 조기 종료 기준\n",
    "best_val_rmse = float(\"inf\")\n",
    "patience = 100\n",
    "trigger_count = 0\n",
    "\n",
    "# 🔹 Transformer 모델 정의\n",
    "class GPTStockPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=11, embed_dim=32, num_heads=8, ff_dim=128, num_layers=1, output_days=100):\n",
    "        super(GPTStockPredictor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, output_days)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "# 🔹 모델 초기화\n",
    "model_class = GPTStockPredictor(output_days=100).to(device)\n",
    "learn_model(model_class, patience=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 레이어 추가 transformer 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_GPTStockPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=11, embed_dim=16, num_heads=8, ff_dim=64, num_layers=1, output_days=50):\n",
    "        super(CNN_GPTStockPredictor, self).__init__()\n",
    "\n",
    "        # ✅ 1D CNN Feature Extractor\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=embed_dim, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=input_dim, out_channels=embed_dim, kernel_size=5, padding=2)\n",
    "        self.conv3 = nn.Conv1d(in_channels=input_dim, out_channels=embed_dim, kernel_size=7, padding=3)\n",
    "        self.conv_merge = nn.Linear(embed_dim * 3, embed_dim)\n",
    "        # self.conv_merge = nn.Linear(embed_dim , embed_dim)\n",
    "\n",
    "        # ✅ Transformer Encoder\n",
    "        self.embedding = nn.Linear(embed_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # ✅ Fully Connected Layer\n",
    "        self.fc = nn.Linear(embed_dim, output_days)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1D CNN Feature Extraction\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, input_dim, sequence_length)\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x)\n",
    "        x3 = self.conv3(x)\n",
    "        x = torch.cat([x1, x2, x3], dim=1)  # (batch_size, embed_dim * 3, sequence_length)\n",
    "        # x = torch.cat([x1], dim=1)  # (batch_size, embed_dim * 3, sequence_length)\n",
    "        x = x.permute(0, 2, 1)  # (batch_size, sequence_length, embed_dim * 3)\n",
    "        x = self.conv_merge(x)  # (batch_size, sequence_length, embed_dim)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)  # (sequence_length, batch_size, embed_dim)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "\n",
    "        # Output Layer\n",
    "        output = self.fc(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkdalsghrj/anaconda3/envs/finpredictor/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], RMSE: 2.7394, MAPE: 154.76%, Val RMSE: 3.4668 (Converted: 31.03), Val RMSE %: 74.11%, Val MAPE: 93.44%\n",
      "Epoch [20/500], RMSE: 2.6170, MAPE: 149.60%, Val RMSE: 3.3076 (Converted: 26.32), Val RMSE %: 62.85%, Val MAPE: 88.27%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 🔹 모델 초기화\n",
    "model_class = CNN_GPTStockPredictor(output_days=100).to(device)\n",
    "learn_model(model_class, patience=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RelativePOsitional 응용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "class RelativePositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim, max_len=5000):\n",
    "        super(RelativePositionalEncoding, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        pe = torch.zeros(max_len, embed_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-np.log(10000.0) / embed_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 성능확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# 🔹 디바이스 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 🔹 Transformer 모델 클래스 정의 (학습한 모델과 동일한 구조)\n",
    "class GPTStockPredictor(nn.Module):\n",
    "    def __init__(self, input_dim=11, embed_dim=32, num_heads=8, ff_dim=128, num_layers=1, output_days=50):\n",
    "        super(GPTStockPredictor, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, embed_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=ff_dim)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Linear(embed_dim, output_days)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)\n",
    "        output = self.fc(x)\n",
    "        return output\n",
    "\n",
    "# 🔹 저장된 모델 불러오기\n",
    "model = GPTStockPredictor(output_days=100).to(device)\n",
    "model.load_state_dict(torch.load(\"best_stock_predictor.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# 🔹 AAPL 주식 데이터 불러오기\n",
    "new_ticker = \"Googl\"\n",
    "stock = yf.Ticker(new_ticker)\n",
    "temp = stock.history(period=\"max\")[[\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]]\n",
    "\n",
    "# 🔹 로그 변환 적용 (✅ MinMax 정규화 제거)\n",
    "df = temp.copy()\n",
    "df[\"Close\"] = np.log1p(df[\"Close\"])  # Close 값 로그 변환\n",
    "\n",
    "# 🔹 이동 평균 및 지표 추가\n",
    "df[\"MA_10\"] = df[\"Close\"].rolling(window=10).mean()\n",
    "df[\"MA_20\"] = df[\"Close\"].rolling(window=20).mean()\n",
    "df[\"STD_10\"] = df[\"Close\"].rolling(window=10).std()\n",
    "df[\"STD_20\"] = df[\"Close\"].rolling(window=20).std()\n",
    "\n",
    "# 🔹 RSI 계산\n",
    "def compute_rsi(data, window=14):\n",
    "    delta = data.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "df[\"RSI_14\"] = compute_rsi(df[\"Close\"], window=14)\n",
    "df[\"MACD\"] = df[\"Close\"].ewm(span=12, adjust=False).mean() - df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "df[\"MACD_Signal\"] = df[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "# 🔹 거래량 이동 평균 및 로그 변환\n",
    "df[\"Volume_MA_10\"] = df[\"Volume\"].rolling(window=10).mean()\n",
    "df[\"Volume_MA_20\"] = df[\"Volume\"].rolling(window=20).mean()\n",
    "df[\"Log_Volume\"] = np.log1p(df[\"Volume\"])\n",
    "\n",
    "# 🔹 NaN 값 제거\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 저장된 정규화 객체 불러오기\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "# ✅ 학습 시 사용한 컬럼 확인\n",
    "train_columns = ['Close','MA_10', 'MA_20', 'STD_10', 'STD_20', 'RSI_14', 'MACD', 'MACD_Signal', 'Volume_MA_10', 'Volume_MA_20', 'Log_Volume']\n",
    "print(\"훈련 데이터에 사용된 컬럼:\", train_columns)\n",
    "\n",
    "# ✅ 테스트 데이터에서 학습 때 사용한 컬럼만 유지\n",
    "df_close = df[[\"Close\"]].copy()  # Close 값 따로 저장 (로그 변환된 상태)\n",
    "df = df[train_columns]  # 훈련에 사용된 컬럼만 선택\n",
    "print(\"테스트 데이터 컬럼 확인:\", df.columns.tolist())  # 확인용 출력\n",
    "\n",
    "\n",
    "\n",
    "# 🔹 저장된 정규화 객체 적용 (✅ Close 값은 정규화 안 함)\n",
    "df_standardized = pd.DataFrame(np.log1p(df), index=df.index, columns=df.columns)\n",
    "\n",
    "df_standardized[df.columns.difference([\"Close\"])] =  np.log1p(df.drop(columns=[\"Close\"]))  # ✅ Close 제외 후 정규화\n",
    "df_standardized[\"Close\"] = df_close[\"Close\"]  # Close는 정규화하지 않고 로그 변환된 값 유지\n",
    "\n",
    "# 🔹 최근 50일 데이터를 입력 데이터로 사용\n",
    "sequence_length = 100\n",
    "X_test = df_standardized.iloc[-sequence_length*2-1:-(sequence_length + 1)].values  # 최근 50일 데이터\n",
    "X_test = np.expand_dims(X_test, axis=0)  # 배치 차원 추가\n",
    "X_test_tensor_2 = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "# 🔹 예측 수행\n",
    "with torch.no_grad():\n",
    "    predicted = model(X_test_tensor_2).cpu().numpy().flatten()\n",
    "\n",
    "# ✅ 예측된 값 복원 (로그 변환 역변환)\n",
    "predicted_prices = np.expm1(predicted)  # ✅ np.expm1() 사용하여 원래 가격으로 변환\n",
    "\n",
    "# ✅ 실제 데이터는 원본 그대로 사용\n",
    "actual_prices = temp[\"Close\"].iloc[-(sequence_length+1):-1].values\n",
    "\n",
    "# ✅ RMSE 계산\n",
    "rmse = np.sqrt(mean_squared_error(actual_prices, predicted_prices))\n",
    "\n",
    "# ✅ MAPE 계산\n",
    "mape = mean_absolute_percentage_error(actual_prices, predicted_prices) * 100  # 퍼센트로 변환\n",
    "\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAPE: {mape:.2f}%\")\n",
    "\n",
    "# ✅ 날짜 설정\n",
    "dates = temp.index[-101:-1]\n",
    "\n",
    "# 🔹 그래프 출력\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(dates, actual_prices, label=\"Actual Prices\", marker=\"o\", linestyle=\"dashed\", color=\"blue\")\n",
    "plt.plot(dates, predicted_prices, label=\"Predicted Prices\", marker=\"s\", linestyle=\"solid\", color=\"red\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(f\"{new_ticker} Stock Price Prediction vs Actual\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
